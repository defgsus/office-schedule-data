{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95423f4b",
   "metadata": {},
   "source": [
    "# Data access\n",
    "\n",
    "All data is presented as CSV files, most of it compressed into `tar.gz` files. For convenient access in Python you can use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c371871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import Data, Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c171c48",
   "metadata": {},
   "source": [
    "## Direct table access\n",
    "\n",
    "Each source (identified by `source_id`) is published as a single CSV file for each week. The CSVs contain the **free dates** that have been reported by the website **at each snapshot time** (typically every 15 minutes) for **each sub-location** ((identified by `location_id`) of the source. Those sub-locations typically are separate offices but can also represent the same office through different schedules or locations in different cities.\n",
    "\n",
    "`source_id` and `location_id` together form the unique ID of one calendar, sampled at the snapshot `date`. \n",
    "\n",
    "Individual tables can be accessed with the `Data.get_table` class method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table for specific calendar week and source_id\n",
    "columns, rows = Data.get_table((2021, 30), \"leipzig\")\n",
    "print(columns[:5])\n",
    "print(rows[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7f55c",
   "metadata": {},
   "source": [
    "Or with the `Data.get_dataframe` class method which returns a [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d398f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.get_dataframe((2021, 30), \"leipzig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a894be",
   "metadata": {},
   "source": [
    "For convenience, both methods support adding the names from the [metadata.json](compressed/metadata.json) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3bdefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.get_dataframe((2021, 30), \"leipzig\", with_meta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2cf3a",
   "metadata": {},
   "source": [
    "Do not worry about all the zeros in there. Look at [\"Plotting the raw data\"](#plotting-the-raw-data) to see the free dates in between them. \n",
    "\n",
    "Dataframes are very useful to analyze the data. For example, we can count the sum of all free dates available for each sub-location with these three lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fdaf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Data.get_dataframe((2021, 30), \"leipzig\", with_meta=True)\n",
    "# sum over each location and accross all available dates \n",
    "loc_sum = df.groupby(\"location_name\").sum().sum(axis=1)\n",
    "# sort and plot\n",
    "loc_sum.sort_values().plot.barh(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d889c",
   "metadata": {},
   "source": [
    "The `date`, `source_id` and `location_id` (as well as `source_name` and `location_name`) columns form a [pandas.MultiIndex](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.html#pandas.MultiIndex) (See [multiindexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#)). The individual values can be accessed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e370449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.get_level_values(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c8aa2",
   "metadata": {},
   "source": [
    "### Note on filters\n",
    "\n",
    "All string filters (for `source_id`, `location_id` or [metric name](#precalculated-metrics-access)) support:\n",
    "\n",
    "- [wildcard matching](https://en.wikipedia.org/wiki/Wildcard_character#File_and_directory_patterns). e.g. `\"bonn*\"` would match `\"bonn\"` and `\"bonnbau\"`\n",
    "- lists of wildcards. e.g. `[\"bonn*\", \"dresden*\"]`\n",
    "- functions. e.g. `lambda n: n.startswith(\"bonn\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fffc415",
   "metadata": {},
   "source": [
    "## Iterate through the data\n",
    "\n",
    "To access all tables in the published dataset you can use the `Data.iter_*` methods. The `Data` class has to be instantiated and will accept *filters* in the constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(source_id=[\"jena\", \"bonn*\"], iso_week_lt=(2021, 30))\n",
    "\n",
    "for week, source_id, fileio in data.iter_files():\n",
    "    print(f\"{week} {source_id:10s} {len(fileio.read())} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3d3f4",
   "metadata": {},
   "source": [
    "The `fileio` parameter is a readable binary stream into each file inside each `tar.gz` archive.\n",
    "\n",
    "The `Data.iter_tables` generator will yield the table data instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a43ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for week, source_id, columns, rows in data.iter_tables():\n",
    "    print(f\"{week} {source_id:10s} {len(rows)} rows x {len(columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc5291",
   "metadata": {},
   "source": [
    "And `iter_dataframes` will yield a `pandas.DataFrame` for each table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "for week, source_id, df in data.iter_dataframes():\n",
    "    print(f\"{week} {source_id:10s} shape={df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13a529",
   "metadata": {},
   "source": [
    "Note that the dataframes have three columns less than the raw tables because the `date`, `source_id` and `location_id` columns are moved to the pandas multiindex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c538c1",
   "metadata": {},
   "source": [
    "The yielded tables or dataframes are always sorted first by week and secondary by source_id. From these tables, it's possible to calculate all kinds of metrics, although it takes some time as the uncompressed tables are gigabytes in size altogether. \n",
    "\n",
    "For the impatient there are some precalcuated metrics contained in this repository.\n",
    "\n",
    "# Precalculated metrics access\n",
    "\n",
    "The available metrics are `free_dates`, `appointments` and `cancellations`. The table rows are the snapshot dates (truncated to exact 15 minutes steps) and the columns contain each metric for each source and sub-location. The column names are concatenated strings of `source_id`/`location_id`/`metric_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0abb80",
   "metadata": {},
   "source": [
    "The above example of free dates per sub-location can also be calculated from the metrics using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7526b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Metrics.dataframe(\"free_dates\", \"leipzig\", iso_week=(2021, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef5315",
   "metadata": {},
   "source": [
    "which gives us the filtered metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff88646",
   "metadata": {},
   "source": [
    "which can likewise be summed and plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15dc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum().sort_values().plot.barh(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78445ac5",
   "metadata": {},
   "source": [
    "### Appointments and cancellations\n",
    "\n",
    "The number of appointments that have been made between two website snapshots, as well as the number of cancelled appointments are estimated from the raw data. \n",
    "\n",
    "For example, we can plot these metrics for all locations of a source, summed for each day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab84d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Metrics.dataframe(\n",
    "    [\"appointments\", \"cancellations\"], \"blankenburg\",\n",
    "    iso_week_gte=(2021, 30), iso_week_lte=(2021, 37),  # put a time range to the returned data\n",
    ")\n",
    "df.resample(\"1d\").sum().plot(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0367fe",
   "metadata": {},
   "source": [
    "### Metrics with timespans\n",
    "\n",
    "All of the metrics are also available according to their distance to the snapshot time. For example, `appointments_0d` holds the number of appointments made at the same day as the snapshot, or `free_dates_1h` holds the number of free dates that are 1 hour apart from the snapshot date. Snapshot and possible appointment dates are quantized\n",
    "to full hours, days or calendar weeks before calculating the distance.\n",
    "\n",
    "Using wildcard matching, we can retrieve all timespans for a certain metric: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221017cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Metrics.dataframe(\n",
    "    [\"appointments_*w\"], \"blankenburg\", \"85150\", \n",
    "    iso_week_gte=(2021, 30), iso_week_lte=(2021, 37),\n",
    ")\n",
    "df.resample(\"1d\").sum().plot(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbaaad4",
   "metadata": {},
   "source": [
    "We can see that appointments made in the same week (`appointments_0w`) are quite rare, and appointments within the next week (`appointments_1w`) are getting rarer while appointments made in the week after next week (`appointments_2w`) are growing.\n",
    "\n",
    "If we compare with the number of free dates available within each weekly timespan, it kind of makes sense and probably is a result of people coming home from holidays and getting busy again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26211aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Metrics.dataframe(\n",
    "    [\"free_dates_*w\"], \"blankenburg\", \"85150\",\n",
    "    iso_week_gte=(2021, 30), iso_week_lte=(2021, 37),\n",
    ")\n",
    "df.resample(\"1d\").sum().plot(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe3277",
   "metadata": {},
   "source": [
    "## Plotting the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4caf3e8",
   "metadata": {},
   "source": [
    "Still, something seems not right there. Best to have a look at the actual free dates. Because it's such an enormous amount of data, a table does not work well. But we can plot something like a heatmap. \n",
    "\n",
    "First find the calendar week of interest. The plot has labeled the 23rd of August in the area of interest. The calendar week is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80335268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.date(2021, 8, 23).isocalendar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142300a",
   "metadata": {},
   "source": [
    "Week 34. Next get a dataframe resampled to 1 hour steps, both for snapshot dates as for free dates, to make it fit better into a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = (\n",
    "    # examine the week before and after as well\n",
    "    pd.concat([\n",
    "        Data.get_dataframe((2021, 33), \"blankenburg\", \"85150\"),\n",
    "        Data.get_dataframe((2021, 34), \"blankenburg\", \"85150\"),\n",
    "        Data.get_dataframe((2021, 35), \"blankenburg\", \"85150\"),\n",
    "    ])\n",
    "    # just keep the \"date\" index\n",
    "    .droplevel([\"source_id\", \"location_id\"])\n",
    "    # resample snapshot date to 1 hour steps\n",
    "    .resample(\"1h\").sum()\n",
    "    # resample possible appointment date to 1 hour steps\n",
    "    .resample(\"1h\", axis=1).sum()\n",
    "    # replace zeros with NaNs which are not plotted\n",
    "    # and make the graphic much more readable\n",
    "    .replace(0, np.nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db2900",
   "metadata": {},
   "source": [
    "I'll use the [plotly](https://plotly.com/python/) library to produce the heatmap because it's less complicted compared to matplotlib. Also, in the jupyter notebook, it's interactive and allows zooming and tooltips per value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71af04b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(\n",
    "    df, aspect=\"auto\", width=1000, height=700, \n",
    "    labels={\"x\": \"appointment date\", \"y\": \"snapshot date\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ae3bc",
   "metadata": {},
   "source": [
    "In the notebook, one could use `fig.show()` to display the interactive plot. However, this does not work in the markdown conversion so we convert the javascript plot to an image (using [kaleido](https://github.com/plotly/Kaleido) in the back)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b19949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(fig.to_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034710d8",
   "metadata": {},
   "source": [
    "Free appointment dates are those vertical lines that come from the top and vanish when either the date has been taken by someone or it's getting close to the actual snapshot time, which means that the date passed unused.\n",
    "\n",
    "Obviously, there is problem here. The free dates in September are not visible in August. Good that we had a look! A [fix](https://github.com/defgsus/office-schedule-scraper/commit/d66d9b815be316857027d501d1131cec7b53f475) is applied, but all **etermin**-based scrapers have produced incomplete snapshots up until now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
