{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f3bc1",
   "metadata": {},
   "source": [
    "# Data access\n",
    "\n",
    "All data is presented as CSV files, most of it compressed into `tar.gz` files. For convenient access in Python you can use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import Data, Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a225d",
   "metadata": {},
   "source": [
    "## Direct table access\n",
    "\n",
    "Each source (identified by `source_id`) is published as a single CSV file for each week. The CSVs contain the **free dates** that have been reported by the website **at each snapshot time** (typically every 15 minutes) for **each sub-location** of the source. Those sub-locations typically are separate offices but can also represent the same office through different schedules or locations in different cities. \n",
    "\n",
    "Individual tables can be accessed with the `Data.get_table` class method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table for specific calendar week and source_id\n",
    "columns, rows = Data.get_table((2021, 30), \"leipzig\")\n",
    "print(columns[:5])\n",
    "print(rows[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5248db8",
   "metadata": {},
   "source": [
    "Or with the `Data.get_dataframe` class method which returns a [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.get_dataframe((2021, 30), \"leipzig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db99eb5e",
   "metadata": {},
   "source": [
    "For convenience, both methods support adding the names from the [metadata.json](compressed/metadata.json) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.get_dataframe((2021, 30), \"leipzig\", with_meta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c0cb7",
   "metadata": {},
   "source": [
    "Dataframes are very useful to analyze the data. For example, we can count the sum of all free dates available for each sub-location with these three lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Data.get_dataframe((2021, 30), \"leipzig\", with_meta=True)\n",
    "# sum over each location and accross all available dates \n",
    "loc_sum = df.groupby(\"location_name\").sum().sum(axis=1)\n",
    "# sort and plot\n",
    "loc_sum.sort_values().plot.barh(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afeba6f",
   "metadata": {},
   "source": [
    "The `date`, `source_id`, `location_id`, `source_name` and `location_name` columns form a [pandas.MultiIndex](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.html#pandas.MultiIndex). The individual values can be accessed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.get_level_values(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e35208",
   "metadata": {},
   "source": [
    "### Note on filters\n",
    "\n",
    "All string filters (for `source_id`, `location_id` or [metric name](#precalculated-metrics-access) support:\n",
    "\n",
    "- [wildcard matching](https://en.wikipedia.org/wiki/Wildcard_character#File_and_directory_patterns). e.g. `\"bonn*\"` would match `\"bonn\"` and `\"bonnbau\"`\n",
    "- lists of wildcards. e.g. `[\"bonn*\", \"dresden*\"]`\n",
    "- functions. e.g. `lambda n: n.startswith(\"bonn\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87881e5",
   "metadata": {},
   "source": [
    "## Iterate through the data\n",
    "\n",
    "To access all tables in the published dataset you can use the `Data.iter_*` methods. The `Data` class has to be instantiated and will accept *filters* in the constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(source_id=[\"jena\", \"bonn*\"], iso_week_lt=(2021, 30))\n",
    "\n",
    "for week, source_id, fileio in data.iter_files():\n",
    "    print(f\"{week} {source_id:10s} {len(fileio.read())} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b0d10",
   "metadata": {},
   "source": [
    "The `fileio` parameter is a readable binary stream into each file inside each `tar.gz` archive.\n",
    "\n",
    "The `Data.iter_tables` generator will yield the table data instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6565bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for week, source_id, columns, rows in data.iter_tables():\n",
    "    print(f\"{week} {source_id:10s} {len(rows)} rows x {len(columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a644c1e",
   "metadata": {},
   "source": [
    "And `iter_dataframes` will yield a `pandas.DataFrame` for each table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "for week, source_id, df in data.iter_dataframes():\n",
    "    print(f\"{week} {source_id:10s} shape={df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a518b",
   "metadata": {},
   "source": [
    "Note that the dataframes have three columns less than the raw tables because the `date`, `source_id` and `location_id` columns are moved to the pandas multiindex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffac24b",
   "metadata": {},
   "source": [
    "The yielded tables or dataframes are always sorted first by week and secondary by source_id. From these tables, it's possible to calculate all kinds of metrics, although it takes some time as the uncompressed tables are gigabytes in size altogether. \n",
    "\n",
    "For the impatient there are some precalcuated metrics contained in this repository.\n",
    "\n",
    "# Precalculated metrics access\n",
    "\n",
    "The available metrics are `free_dates`, `appointments` and `cancellations`. The table rows are the snapshot dates (truncated to exact 15 minutes steps) and the columns contain each metric for each source and sub-location. The column names are concatenated strings of `source_id`/`location_id`/`metric_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f6d44",
   "metadata": {},
   "source": [
    "The above example of free dates per sub-location can also be calculated from the metrics using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c0083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Metrics.dataframe(\"free_dates\", \"leipzig\", iso_week=(2021, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eef7f0",
   "metadata": {},
   "source": [
    "which gives us the filtered metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da8a3f",
   "metadata": {},
   "source": [
    "which can likewise be summed and plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum().sort_values().plot.barh(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f6c5f",
   "metadata": {},
   "source": [
    "### Appointments and cancellations\n",
    "\n",
    "The number of appointments that have been made between two website snapshots, as well as the number of cancelled appointments are estimated from the raw data. \n",
    "\n",
    "For example, we can plot these metrics for all locations of a source, summed for each day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Metrics.dataframe(\n",
    "    [\"appointments\", \"cancellations\"], \"blankenburg\",\n",
    "    iso_week_gte=(2021, 30), iso_week_lte=(2021, 37),  # put a time range to the returned data\n",
    ")\n",
    "df.resample(\"1d\").sum().plot(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c126c187",
   "metadata": {},
   "source": [
    "### Metrics with timespans\n",
    "\n",
    "All of the metrics are also available according to their distance to the snapshot time. For example, `appointments_0d` holds the number of appointments made at the same day as the snapshot, or `free_dates_1h` holds the number of free dates that are 1 hour apart from the snapshot date. Snapshot and possible appointment dates are quantized\n",
    "to full hours, days or calendar weeks before calculating the distance.\n",
    "\n",
    "Using wildcard matching, we can retrieve all timespans for a certain metric: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdbf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Metrics.dataframe(\n",
    "    [\"appointments_*w\"], \"blankenburg\", \"85150\", \n",
    "    iso_week_gte=(2021, 30), iso_week_lte=(2021, 37),\n",
    ")\n",
    "df.resample(\"1d\").sum().plot(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645036b0",
   "metadata": {},
   "source": [
    "We can see that appointments made in the same week (`appointments_0w`) are quite rare, and appointments within the next week (`appointments_1w`) are getting rarer while appointments made in the week after next week (`appointments_2w`) are growing.\n",
    "\n",
    "If we compare with the number of free dates available within each weekly timespan, it kind of makes sense and probably is a result of people coming home from holidays and getting busy again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Metrics.dataframe(\n",
    "    [\"free_dates_*w\"], \"blankenburg\", \"85150\",\n",
    "    iso_week_gte=(2021, 30), iso_week_lte=(2021, 37),\n",
    ")\n",
    "df.resample(\"1d\").sum().plot(figsize=(16, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
